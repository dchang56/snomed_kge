{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset, RandomSampler\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, p=0.9):\n",
    "    train_size = int(len(df)*p)\n",
    "    train = df[:train_size]\n",
    "    test = df[train_size:]\n",
    "    train_labels = train.pop('labels')\n",
    "    test_labels = test.pop('labels')\n",
    "    return train, test, train_labels, test_labels\n",
    "\n",
    "## Define simple model to do n-class classification\n",
    "class NodeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_labels):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.input_dim, self.num_labels)\n",
    "    \n",
    "    def forward(self, inputs, labels=None):\n",
    "        inputs = self.dropout(inputs)\n",
    "        logits = self.classifier(inputs)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class NodeClassifier2(nn.Module):\n",
    "    def __init__(self, input_dim, num_labels):\n",
    "        super(NodeClassifier2, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.layer1 = nn.Linear(self.input_dim, 64)\n",
    "        self.classifier = nn.Linear(64, self.num_labels)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs, labels=None):\n",
    "        logits = self.classifier(self.activation(self.layer1(self.dropout(inputs))))\n",
    "                \n",
    "        \n",
    "        return logits\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    results = {}\n",
    "    \n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in dataloader:\n",
    "        model.eval()\n",
    "        inputs, labels = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs)\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = labels.detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, labels.detach().cpu().numpy(), axis=0)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    result = (preds==out_label_ids).mean()\n",
    "    results['acc'] = result\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up paths\n",
    "embeddings_dir = '/home/dc925/project/data/embeddings'\n",
    "\n",
    "snomed2vec_emb_file = os.path.join(embeddings_dir, 'snomed2vec/Node2Vec/snomed2vec.txt')\n",
    "cui2vec_emb_file = os.path.join(embeddings_dir, 'cui2vec/cui2vec_pretrained.csv')\n",
    "kge_models = ['TransE', 'DistMult', 'SimplE', 'ComplEx', 'RotatE']\n",
    "kge_models_paths = {}\n",
    "for m in kge_models:\n",
    "    kge_models_paths[m] = os.path.join(embeddings_dir, 'kge/{}.pkl'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransE': '/home/dc925/project/data/embeddings/kge/TransE.pkl',\n",
       " 'DistMult': '/home/dc925/project/data/embeddings/kge/DistMult.pkl',\n",
       " 'SimplE': '/home/dc925/project/data/embeddings/kge/SimplE.pkl',\n",
       " 'ComplEx': '/home/dc925/project/data/embeddings/kge/ComplEx.pkl',\n",
       " 'RotatE': '/home/dc925/project/data/embeddings/kge/RotatE.pkl'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kge_models_paths;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dc925/miniconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "## Load in mappings\n",
    "\n",
    "# scui to cui map\n",
    "scui2cui = pd.read_csv(os.path.join(embeddings_dir, 'snomed2vec/concept_maps/cui_scui.tsv'), sep='\\t', header=None)\n",
    "scui2cui = scui2cui[:-1]\n",
    "scui2cui.columns = ['CUI', 'SCUI']\n",
    "scui2cui = scui2cui.set_index('SCUI')['CUI'].to_dict()\n",
    "# cui to semtype and semgroup maps\n",
    "# cui2semtype = pd.read_csv('/home/dc925/project/data/embeddings/snomed2vec/concept_maps/cui_node_type.tsv', sep='\\t', header= None)\n",
    "# cui2semtype.columns = ['CUI', 'TYPE']\n",
    "# cui2semtype = cui2semtype[-cui2semtype.duplicated()]\n",
    "# cui2semtype = cui2semtype.set_index('CUI')['TYPE'].to_dict()\n",
    "semantic_info = pd.read_csv('/home/dc925/project/clinical_kge/semantic_info.csv', sep='\\t', index_col=0)\n",
    "semantic_info = semantic_info.drop_duplicates(subset='CUI')\n",
    "cui2sty = semantic_info.set_index('CUI')['STY'].to_dict()\n",
    "cui2sg = semantic_info.set_index('CUI')['SemGroup'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading TransE\n",
      "loading DistMult\n",
      "loading SimplE\n",
      "loading ComplEx\n",
      "loading RotatE\n"
     ]
    }
   ],
   "source": [
    "## Load in embeddings\n",
    "\n",
    "# load in snomed2vec\n",
    "snomed2vec = {}\n",
    "with open(snomed2vec_emb_file, 'r') as fin:\n",
    "    for i, line in enumerate(fin):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        line = line.strip().split()\n",
    "        scui = int(line[0])\n",
    "        embedding = np.array(line[1:], dtype=float)\n",
    "        if scui in scui2cui:\n",
    "            snomed2vec[scui2cui[scui]] = embedding\n",
    "snomed2vec = pd.DataFrame.from_dict(snomed2vec, orient='index')\n",
    "\n",
    "# load in cui2vec\n",
    "cui2vec = pd.read_csv(cui2vec_emb_file, index_col=0)\n",
    "\n",
    "# load in kge\n",
    "kge_embeddings = {}\n",
    "for m, p in kge_models_paths.items():\n",
    "    print('loading {}'.format(m))\n",
    "    with open(p, 'rb') as fin:\n",
    "        model = pickle.load(fin)\n",
    "        embeddings = model.solver.entity_embeddings\n",
    "        embeddings = pd.DataFrame(embeddings)\n",
    "        embeddings['CUI'] = [model.graph.id2entity[i] for i in range(len(embeddings))]\n",
    "#         model_dict = {model.graph.id2entity[i]: embeddings[i] for i in range(len(embeddings))}\n",
    "        embeddings = embeddings.set_index('CUI')\n",
    "    kge_embeddings[m] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snomed2vec.to_csv(os.path.join(embeddings_dir, 'snomed2vec/snomed2vec.csv'), sep='\\t', header=None) #this is for ease of repeated use of snomed2vec, i.e. for viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get intersecting CUIs and subset\n",
    "\n",
    "cuis_intersection = list(set(kge_embeddings['TransE'].index) & set(cui2vec.index) & set(snomed2vec.index) - set(['C0015919']))\n",
    "random.seed(42)\n",
    "random.shuffle(cuis_intersection)\n",
    "\n",
    "snomed2vec = snomed2vec.loc[cuis_intersection]\n",
    "cui2vec = cui2vec.loc[cuis_intersection]\n",
    "for m in kge_models:\n",
    "    kge_embeddings[m] = kge_embeddings[m].loc[cuis_intersection]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving each embedding file w identical concepts list\n",
    "snomed2vec.to_csv('notebooks/embeddings_for_bootstrapping/snomed2vec.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui2vec.to_csv('notebooks/embeddings_for_bootstrapping/cui2vec_pretrained.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in kge_models:\n",
    "    kge_embeddings[model].to_csv('notebooks/embeddings_for_bootstrapping/{}.csv'.format(model), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get corresponding semantic type labels\n",
    "# labels = [cui2sg[cui] for cui in cuis_intersection]\n",
    "labels = [cui2sty[cui] for cui in cuis_intersection]\n",
    "label_map = {label: i for i, label in enumerate(np.unique(labels))}\n",
    "\n",
    "models = {m:kge_embeddings[m] for m in kge_models}\n",
    "models['snomed2vec'] = snomed2vec\n",
    "models['cui2vec'] = cui2vec\n",
    "for name, model in models.items():\n",
    "    model['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease or Syndrome                        6857\n",
       "Organic Chemical                           3558\n",
       "Finding                                    3257\n",
       "Amino Acid, Peptide, or Protein            1970\n",
       "Body Part, Organ, or Organ Component       1874\n",
       "Injury or Poisoning                        1862\n",
       "Therapeutic or Preventive Procedure        1814\n",
       "Neoplastic Process                         1672\n",
       "Pathologic Function                        1246\n",
       "Congenital Abnormality                      797\n",
       "Sign or Symptom                             751\n",
       "Laboratory Procedure                        554\n",
       "Mental or Behavioral Dysfunction            553\n",
       "Diagnostic Procedure                        513\n",
       "Pharmacologic Substance                     415\n",
       "Body Location or Region                     311\n",
       "Acquired Abnormality                        302\n",
       "Body Space or Junction                      256\n",
       "Anatomical Abnormality                      256\n",
       "Health Care Activity                        229\n",
       "Body Substance                              170\n",
       "Nucleic Acid, Nucleoside, or Nucleotide     151\n",
       "Tissue                                      136\n",
       "Clinical Drug                               100\n",
       "Cell or Molecular Dysfunction                80\n",
       "Hazardous or Poisonous Substance             68\n",
       "Indicator, Reagent, or Diagnostic Aid        65\n",
       "Inorganic Chemical                           64\n",
       "Immunologic Factor                           55\n",
       "Body System                                  48\n",
       "Biologically Active Substance                41\n",
       "Educational Activity                         29\n",
       "Biomedical or Dental Material                11\n",
       "Hormone                                       8\n",
       "Anatomical Structure                          8\n",
       "Molecular Biology Research Technique          4\n",
       "Research Activity                             4\n",
       "Antibiotic                                    3\n",
       "Vitamin                                       1\n",
       "Fully Formed Anatomical Structure             1\n",
       "Element, Ion, or Isotope                      1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['TransE']['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V491</th>\n",
       "      <th>V492</th>\n",
       "      <th>V493</th>\n",
       "      <th>V494</th>\n",
       "      <th>V495</th>\n",
       "      <th>V496</th>\n",
       "      <th>V497</th>\n",
       "      <th>V498</th>\n",
       "      <th>V499</th>\n",
       "      <th>V500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C0443935</td>\n",
       "      <td>-0.017254</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>-8.413409e-17</td>\n",
       "      <td>-0.011074</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>1.561251e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.062629</td>\n",
       "      <td>0.055867</td>\n",
       "      <td>-0.009603</td>\n",
       "      <td>-0.084995</td>\n",
       "      <td>-0.025543</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>0.044795</td>\n",
       "      <td>0.057199</td>\n",
       "      <td>-0.036408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0228201</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>1.116728e-17</td>\n",
       "      <td>-0.001626</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>-0.003508</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>1.375310e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.042257</td>\n",
       "      <td>0.057367</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.052230</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.053433</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>-0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0269672</td>\n",
       "      <td>-0.180031</td>\n",
       "      <td>-0.192788</td>\n",
       "      <td>-4.732326e-15</td>\n",
       "      <td>-1.444332</td>\n",
       "      <td>0.250273</td>\n",
       "      <td>-0.728043</td>\n",
       "      <td>-1.311989</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.045558</td>\n",
       "      <td>2.144118e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>0.074014</td>\n",
       "      <td>0.017153</td>\n",
       "      <td>-0.087824</td>\n",
       "      <td>0.038558</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0.224950</td>\n",
       "      <td>-0.013966</td>\n",
       "      <td>0.105538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0010042</td>\n",
       "      <td>-0.041295</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>-1.966201e-16</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.082290</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>0.056868</td>\n",
       "      <td>1.278708e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.131027</td>\n",
       "      <td>0.136996</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.055677</td>\n",
       "      <td>-0.006197</td>\n",
       "      <td>0.030585</td>\n",
       "      <td>-0.003776</td>\n",
       "      <td>-0.041328</td>\n",
       "      <td>0.079009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0496763</td>\n",
       "      <td>-1.571538</td>\n",
       "      <td>-0.800497</td>\n",
       "      <td>1.998401e-15</td>\n",
       "      <td>-0.071885</td>\n",
       "      <td>-0.783863</td>\n",
       "      <td>0.706583</td>\n",
       "      <td>-0.033649</td>\n",
       "      <td>0.108674</td>\n",
       "      <td>0.357236</td>\n",
       "      <td>-6.661338e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207904</td>\n",
       "      <td>-0.474824</td>\n",
       "      <td>0.452711</td>\n",
       "      <td>0.058087</td>\n",
       "      <td>-0.683948</td>\n",
       "      <td>0.129327</td>\n",
       "      <td>-0.169678</td>\n",
       "      <td>0.776891</td>\n",
       "      <td>-0.183082</td>\n",
       "      <td>-0.159835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0023755</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>-1.338990e-17</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>2.406929e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031750</td>\n",
       "      <td>-0.023817</td>\n",
       "      <td>-0.059648</td>\n",
       "      <td>0.062411</td>\n",
       "      <td>0.025560</td>\n",
       "      <td>-0.023620</td>\n",
       "      <td>0.038617</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.045233</td>\n",
       "      <td>-0.013449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0936139</td>\n",
       "      <td>-0.011319</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>-9.540979e-18</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052012</td>\n",
       "      <td>-0.033416</td>\n",
       "      <td>-0.025539</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.040574</td>\n",
       "      <td>-0.029975</td>\n",
       "      <td>-0.014550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0030569</td>\n",
       "      <td>-4.640131</td>\n",
       "      <td>2.663372</td>\n",
       "      <td>-1.137979e-15</td>\n",
       "      <td>1.207900</td>\n",
       "      <td>0.207284</td>\n",
       "      <td>0.580321</td>\n",
       "      <td>-0.928158</td>\n",
       "      <td>-0.411286</td>\n",
       "      <td>0.519693</td>\n",
       "      <td>1.443290e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573119</td>\n",
       "      <td>0.190212</td>\n",
       "      <td>-0.192988</td>\n",
       "      <td>0.162159</td>\n",
       "      <td>-0.205319</td>\n",
       "      <td>-0.202873</td>\n",
       "      <td>0.262925</td>\n",
       "      <td>0.152719</td>\n",
       "      <td>0.227312</td>\n",
       "      <td>0.403281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0018546</td>\n",
       "      <td>-0.043551</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>-1.734723e-17</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>-0.028119</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>-0.020914</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>4.059253e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117871</td>\n",
       "      <td>0.098924</td>\n",
       "      <td>-0.005892</td>\n",
       "      <td>-0.068078</td>\n",
       "      <td>-0.125509</td>\n",
       "      <td>-0.059967</td>\n",
       "      <td>-0.050742</td>\n",
       "      <td>0.057204</td>\n",
       "      <td>0.166450</td>\n",
       "      <td>-0.100283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0154685</td>\n",
       "      <td>-2.532033</td>\n",
       "      <td>2.371916</td>\n",
       "      <td>-5.273559e-16</td>\n",
       "      <td>0.995882</td>\n",
       "      <td>0.300295</td>\n",
       "      <td>-0.399720</td>\n",
       "      <td>-1.123946</td>\n",
       "      <td>-0.861608</td>\n",
       "      <td>0.242876</td>\n",
       "      <td>4.357625e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>-0.038979</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>-0.179359</td>\n",
       "      <td>0.116830</td>\n",
       "      <td>0.021977</td>\n",
       "      <td>0.052699</td>\n",
       "      <td>-0.067354</td>\n",
       "      <td>-0.059820</td>\n",
       "      <td>-0.082548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30095 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V1        V2            V3        V4        V5        V6  \\\n",
       "C0443935 -0.017254  0.008221 -8.413409e-17 -0.011074 -0.002464  0.016044   \n",
       "C0228201 -0.001670  0.001422  1.116728e-17 -0.001626  0.002968  0.001928   \n",
       "C0269672 -0.180031 -0.192788 -4.732326e-15 -1.444332  0.250273 -0.728043   \n",
       "C0010042 -0.041295  0.034836 -1.966201e-16 -0.031706  0.025178  0.082290   \n",
       "C0496763 -1.571538 -0.800497  1.998401e-15 -0.071885 -0.783863  0.706583   \n",
       "...            ...       ...           ...       ...       ...       ...   \n",
       "C0023755 -0.002035  0.001601 -1.338990e-17 -0.003740  0.000244  0.002646   \n",
       "C0936139 -0.011319  0.003691 -9.540979e-18 -0.000172  0.006309  0.007840   \n",
       "C0030569 -4.640131  2.663372 -1.137979e-15  1.207900  0.207284  0.580321   \n",
       "C0018546 -0.043551  0.016760 -1.734723e-17  0.014421 -0.002491 -0.028119   \n",
       "C0154685 -2.532033  2.371916 -5.273559e-16  0.995882  0.300295 -0.399720   \n",
       "\n",
       "                V7        V8        V9           V10  ...      V491      V492  \\\n",
       "C0443935  0.003069  0.011504  0.003296  1.561251e-17  ...  0.001396  0.062629   \n",
       "C0228201  0.003999 -0.003508  0.009028  1.375310e-16  ...  0.004589  0.042257   \n",
       "C0269672 -1.311989  0.328245  0.045558  2.144118e-15  ...  0.014824 -0.004525   \n",
       "C0010042  0.040825 -0.008587  0.056868  1.278708e-15  ...  0.070307  0.131027   \n",
       "C0496763 -0.033649  0.108674  0.357236 -6.661338e-16  ... -0.207904 -0.474824   \n",
       "...            ...       ...       ...           ...  ...       ...       ...   \n",
       "C0023755  0.004495  0.000083  0.006649  2.406929e-17  ... -0.031750 -0.023817   \n",
       "C0936139  0.000143 -0.000045 -0.000561  0.000000e+00  ... -0.052012 -0.033416   \n",
       "C0030569 -0.928158 -0.411286  0.519693  1.443290e-14  ... -0.573119  0.190212   \n",
       "C0018546  0.003232 -0.020914  0.051351  4.059253e-16  ...  0.117871  0.098924   \n",
       "C0154685 -1.123946 -0.861608  0.242876  4.357625e-15  ...  0.031525 -0.038979   \n",
       "\n",
       "              V493      V494      V495      V496      V497      V498  \\\n",
       "C0443935  0.055867 -0.009603 -0.084995 -0.025543 -0.024957  0.044795   \n",
       "C0228201  0.057367  0.032100 -0.068330 -0.052230  0.027640  0.053433   \n",
       "C0269672  0.074014  0.017153 -0.087824  0.038558 -0.001647  0.224950   \n",
       "C0010042  0.136996  0.025898  0.055677 -0.006197  0.030585 -0.003776   \n",
       "C0496763  0.452711  0.058087 -0.683948  0.129327 -0.169678  0.776891   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "C0023755 -0.059648  0.062411  0.025560 -0.023620  0.038617  0.001838   \n",
       "C0936139 -0.025539  0.022128  0.047825 -0.001195  0.025920 -0.040574   \n",
       "C0030569 -0.192988  0.162159 -0.205319 -0.202873  0.262925  0.152719   \n",
       "C0018546 -0.005892 -0.068078 -0.125509 -0.059967 -0.050742  0.057204   \n",
       "C0154685  0.004401 -0.179359  0.116830  0.021977  0.052699 -0.067354   \n",
       "\n",
       "              V499      V500  \n",
       "C0443935  0.057199 -0.036408  \n",
       "C0228201  0.014709 -0.002867  \n",
       "C0269672 -0.013966  0.105538  \n",
       "C0010042 -0.041328  0.079009  \n",
       "C0496763 -0.183082 -0.159835  \n",
       "...            ...       ...  \n",
       "C0023755  0.045233 -0.013449  \n",
       "C0936139 -0.029975 -0.014550  \n",
       "C0030569  0.227312  0.403281  \n",
       "C0018546  0.166450 -0.100283  \n",
       "C0154685 -0.059820 -0.082548  \n",
       "\n",
       "[30095 rows x 500 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cui2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C0443935</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.227081</td>\n",
       "      <td>-0.228218</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.182619</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>-0.356819</td>\n",
       "      <td>0.116498</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>-0.437398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031006</td>\n",
       "      <td>0.758379</td>\n",
       "      <td>-0.012824</td>\n",
       "      <td>0.439657</td>\n",
       "      <td>0.062407</td>\n",
       "      <td>0.193092</td>\n",
       "      <td>-0.235947</td>\n",
       "      <td>-0.029845</td>\n",
       "      <td>0.121454</td>\n",
       "      <td>-0.076669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0228201</td>\n",
       "      <td>0.524431</td>\n",
       "      <td>0.312281</td>\n",
       "      <td>-0.417633</td>\n",
       "      <td>-0.240308</td>\n",
       "      <td>-0.109762</td>\n",
       "      <td>0.459223</td>\n",
       "      <td>-0.356220</td>\n",
       "      <td>-0.023537</td>\n",
       "      <td>0.587343</td>\n",
       "      <td>-0.249630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235096</td>\n",
       "      <td>0.138988</td>\n",
       "      <td>-0.147969</td>\n",
       "      <td>-0.386817</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>-0.435164</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>0.368568</td>\n",
       "      <td>-0.041101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0269672</td>\n",
       "      <td>0.619270</td>\n",
       "      <td>-0.019828</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.106377</td>\n",
       "      <td>-0.170606</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>-0.216165</td>\n",
       "      <td>0.085807</td>\n",
       "      <td>0.237098</td>\n",
       "      <td>-0.195784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086883</td>\n",
       "      <td>0.296947</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>-0.276423</td>\n",
       "      <td>0.236906</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>-0.367586</td>\n",
       "      <td>-0.270690</td>\n",
       "      <td>-0.408692</td>\n",
       "      <td>0.106499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0010042</td>\n",
       "      <td>0.174152</td>\n",
       "      <td>-0.033354</td>\n",
       "      <td>-0.019611</td>\n",
       "      <td>-0.138394</td>\n",
       "      <td>-0.133457</td>\n",
       "      <td>0.364476</td>\n",
       "      <td>-0.167052</td>\n",
       "      <td>-0.157165</td>\n",
       "      <td>0.177113</td>\n",
       "      <td>0.200517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069982</td>\n",
       "      <td>0.170885</td>\n",
       "      <td>-0.418300</td>\n",
       "      <td>0.050114</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.310699</td>\n",
       "      <td>-0.089806</td>\n",
       "      <td>-0.144133</td>\n",
       "      <td>0.173289</td>\n",
       "      <td>-0.200281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0496763</td>\n",
       "      <td>0.124313</td>\n",
       "      <td>0.238585</td>\n",
       "      <td>0.115642</td>\n",
       "      <td>-0.199571</td>\n",
       "      <td>-0.351034</td>\n",
       "      <td>0.089719</td>\n",
       "      <td>-0.251198</td>\n",
       "      <td>0.150077</td>\n",
       "      <td>-0.096325</td>\n",
       "      <td>-0.606303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244622</td>\n",
       "      <td>0.189515</td>\n",
       "      <td>0.036486</td>\n",
       "      <td>-0.307186</td>\n",
       "      <td>0.370290</td>\n",
       "      <td>0.391348</td>\n",
       "      <td>-0.220769</td>\n",
       "      <td>-0.190920</td>\n",
       "      <td>0.181331</td>\n",
       "      <td>0.074503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0023755</td>\n",
       "      <td>0.028931</td>\n",
       "      <td>-0.016492</td>\n",
       "      <td>-0.722396</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>-0.162352</td>\n",
       "      <td>-0.545657</td>\n",
       "      <td>-0.028831</td>\n",
       "      <td>0.217093</td>\n",
       "      <td>-0.082749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099555</td>\n",
       "      <td>0.518899</td>\n",
       "      <td>-0.090963</td>\n",
       "      <td>-0.196097</td>\n",
       "      <td>-0.345124</td>\n",
       "      <td>0.315299</td>\n",
       "      <td>-0.202121</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.033182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0936139</td>\n",
       "      <td>-0.126591</td>\n",
       "      <td>0.267098</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>-0.361387</td>\n",
       "      <td>0.328127</td>\n",
       "      <td>-0.376621</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>0.501816</td>\n",
       "      <td>-0.346451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130774</td>\n",
       "      <td>0.503798</td>\n",
       "      <td>0.372493</td>\n",
       "      <td>-0.569864</td>\n",
       "      <td>-0.187750</td>\n",
       "      <td>0.297392</td>\n",
       "      <td>-0.034855</td>\n",
       "      <td>-0.110204</td>\n",
       "      <td>0.131759</td>\n",
       "      <td>-0.030913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0030569</td>\n",
       "      <td>0.405239</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>-0.194067</td>\n",
       "      <td>0.148784</td>\n",
       "      <td>0.157940</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>-0.570809</td>\n",
       "      <td>-0.115324</td>\n",
       "      <td>0.476091</td>\n",
       "      <td>-0.386193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130107</td>\n",
       "      <td>0.151192</td>\n",
       "      <td>0.203324</td>\n",
       "      <td>-0.259831</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>-0.105415</td>\n",
       "      <td>-0.147096</td>\n",
       "      <td>0.185738</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.080883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0018546</td>\n",
       "      <td>0.282159</td>\n",
       "      <td>0.084547</td>\n",
       "      <td>-0.060834</td>\n",
       "      <td>0.260427</td>\n",
       "      <td>0.088809</td>\n",
       "      <td>0.543984</td>\n",
       "      <td>-0.333859</td>\n",
       "      <td>-0.239688</td>\n",
       "      <td>0.313252</td>\n",
       "      <td>-0.355661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.160503</td>\n",
       "      <td>0.530713</td>\n",
       "      <td>-0.475399</td>\n",
       "      <td>-0.599489</td>\n",
       "      <td>0.259753</td>\n",
       "      <td>-0.049854</td>\n",
       "      <td>-0.037934</td>\n",
       "      <td>0.441254</td>\n",
       "      <td>-0.153263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0154685</td>\n",
       "      <td>0.371448</td>\n",
       "      <td>-0.029650</td>\n",
       "      <td>-0.171497</td>\n",
       "      <td>-0.392505</td>\n",
       "      <td>-0.312591</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>-0.334433</td>\n",
       "      <td>-0.260825</td>\n",
       "      <td>0.523640</td>\n",
       "      <td>-0.366477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049084</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>-0.166654</td>\n",
       "      <td>-0.171758</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>-0.454778</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>-0.260432</td>\n",
       "      <td>-0.065740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30095 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5    \\\n",
       "C0443935  0.006983  0.227081 -0.228218  0.033706  0.182619 -0.018154   \n",
       "C0228201  0.524431  0.312281 -0.417633 -0.240308 -0.109762  0.459223   \n",
       "C0269672  0.619270 -0.019828  0.011866  0.106377 -0.170606  0.310345   \n",
       "C0010042  0.174152 -0.033354 -0.019611 -0.138394 -0.133457  0.364476   \n",
       "C0496763  0.124313  0.238585  0.115642 -0.199571 -0.351034  0.089719   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "C0023755  0.028931 -0.016492 -0.722396  0.114977  0.018558 -0.162352   \n",
       "C0936139 -0.126591  0.267098  0.120419  0.237915 -0.361387  0.328127   \n",
       "C0030569  0.405239  0.218418 -0.194067  0.148784  0.157940  0.221929   \n",
       "C0018546  0.282159  0.084547 -0.060834  0.260427  0.088809  0.543984   \n",
       "C0154685  0.371448 -0.029650 -0.171497 -0.392505 -0.312591  0.498507   \n",
       "\n",
       "               6         7         8         9    ...       190       191  \\\n",
       "C0443935 -0.356819  0.116498  0.122230 -0.437398  ...  0.031006  0.758379   \n",
       "C0228201 -0.356220 -0.023537  0.587343 -0.249630  ...  0.235096  0.138988   \n",
       "C0269672 -0.216165  0.085807  0.237098 -0.195784  ... -0.086883  0.296947   \n",
       "C0010042 -0.167052 -0.157165  0.177113  0.200517  ...  0.069982  0.170885   \n",
       "C0496763 -0.251198  0.150077 -0.096325 -0.606303  ...  0.244622  0.189515   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "C0023755 -0.545657 -0.028831  0.217093 -0.082749  ... -0.099555  0.518899   \n",
       "C0936139 -0.376621 -0.009967  0.501816 -0.346451  ...  0.130774  0.503798   \n",
       "C0030569 -0.570809 -0.115324  0.476091 -0.386193  ...  0.130107  0.151192   \n",
       "C0018546 -0.333859 -0.239688  0.313252 -0.355661  ...  0.005109  0.160503   \n",
       "C0154685 -0.334433 -0.260825  0.523640 -0.366477  ... -0.049084  0.176079   \n",
       "\n",
       "               192       193       194       195       196       197  \\\n",
       "C0443935 -0.012824  0.439657  0.062407  0.193092 -0.235947 -0.029845   \n",
       "C0228201 -0.147969 -0.386817  0.018341  0.067686 -0.435164  0.064783   \n",
       "C0269672  0.006707 -0.276423  0.236906  0.256283 -0.367586 -0.270690   \n",
       "C0010042 -0.418300  0.050114  0.165173  0.310699 -0.089806 -0.144133   \n",
       "C0496763  0.036486 -0.307186  0.370290  0.391348 -0.220769 -0.190920   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "C0023755 -0.090963 -0.196097 -0.345124  0.315299 -0.202121 -0.024957   \n",
       "C0936139  0.372493 -0.569864 -0.187750  0.297392 -0.034855 -0.110204   \n",
       "C0030569  0.203324 -0.259831  0.017045 -0.105415 -0.147096  0.185738   \n",
       "C0018546  0.530713 -0.475399 -0.599489  0.259753 -0.049854 -0.037934   \n",
       "C0154685  0.010170 -0.166654 -0.171758  0.015612 -0.454778  0.042877   \n",
       "\n",
       "               198       199  \n",
       "C0443935  0.121454 -0.076669  \n",
       "C0228201  0.368568 -0.041101  \n",
       "C0269672 -0.408692  0.106499  \n",
       "C0010042  0.173289 -0.200281  \n",
       "C0496763  0.181331  0.074503  \n",
       "...            ...       ...  \n",
       "C0023755  0.004487  0.033182  \n",
       "C0936139  0.131759 -0.030913  \n",
       "C0030569  0.001776 -0.080883  \n",
       "C0018546  0.441254 -0.153263  \n",
       "C0154685 -0.260432 -0.065740  \n",
       "\n",
       "[30095 rows x 200 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snomed2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C0443935</td>\n",
       "      <td>-0.005615</td>\n",
       "      <td>0.053907</td>\n",
       "      <td>0.064127</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>-0.012609</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>-0.030486</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>-0.011773</td>\n",
       "      <td>0.035155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027201</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>-0.017699</td>\n",
       "      <td>-0.050566</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>-0.039818</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.046554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0228201</td>\n",
       "      <td>0.056639</td>\n",
       "      <td>0.024973</td>\n",
       "      <td>0.043039</td>\n",
       "      <td>-0.010606</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>-0.005639</td>\n",
       "      <td>-0.012716</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.013446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-0.021831</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>-0.042337</td>\n",
       "      <td>0.015798</td>\n",
       "      <td>-0.023749</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>0.094336</td>\n",
       "      <td>0.010797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0269672</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.035234</td>\n",
       "      <td>-0.005638</td>\n",
       "      <td>0.052735</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>-0.034095</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>-0.006118</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013453</td>\n",
       "      <td>0.033583</td>\n",
       "      <td>-0.053264</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.029924</td>\n",
       "      <td>-0.042194</td>\n",
       "      <td>-0.005361</td>\n",
       "      <td>-0.005018</td>\n",
       "      <td>-0.019387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0010042</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>-0.007816</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>-0.019536</td>\n",
       "      <td>-0.018363</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>-0.018858</td>\n",
       "      <td>-0.015806</td>\n",
       "      <td>-0.023911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058378</td>\n",
       "      <td>-0.045572</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.016206</td>\n",
       "      <td>-0.040299</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.001495</td>\n",
       "      <td>0.043285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0496763</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>-0.022139</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>-0.004436</td>\n",
       "      <td>-0.003643</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>-0.109941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010080</td>\n",
       "      <td>0.062235</td>\n",
       "      <td>-0.018077</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>-0.048640</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>-0.063896</td>\n",
       "      <td>-0.019638</td>\n",
       "      <td>0.014158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0023755</td>\n",
       "      <td>-0.040562</td>\n",
       "      <td>-0.008575</td>\n",
       "      <td>-0.029939</td>\n",
       "      <td>-0.030448</td>\n",
       "      <td>-0.014047</td>\n",
       "      <td>-0.035917</td>\n",
       "      <td>-0.040634</td>\n",
       "      <td>-0.004045</td>\n",
       "      <td>-0.017335</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020937</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>0.027856</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>-0.024980</td>\n",
       "      <td>-0.030805</td>\n",
       "      <td>-0.022126</td>\n",
       "      <td>-0.010326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0936139</td>\n",
       "      <td>-0.064008</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>-0.021988</td>\n",
       "      <td>-0.007444</td>\n",
       "      <td>-0.018371</td>\n",
       "      <td>-0.035955</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.025604</td>\n",
       "      <td>-0.003902</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>-0.015511</td>\n",
       "      <td>-0.048765</td>\n",
       "      <td>-0.012535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0030569</td>\n",
       "      <td>-0.002874</td>\n",
       "      <td>-0.014771</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>0.051636</td>\n",
       "      <td>0.058948</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>-0.007807</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.027136</td>\n",
       "      <td>0.018170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019772</td>\n",
       "      <td>-0.030501</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>-0.005095</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.015331</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>0.015845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0018546</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>-0.026229</td>\n",
       "      <td>0.087175</td>\n",
       "      <td>-0.021138</td>\n",
       "      <td>-0.013072</td>\n",
       "      <td>-0.026806</td>\n",
       "      <td>-0.016932</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>0.048636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>-0.008057</td>\n",
       "      <td>0.024764</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>0.024149</td>\n",
       "      <td>-0.010890</td>\n",
       "      <td>0.018251</td>\n",
       "      <td>0.030575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C0154685</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.044326</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.031104</td>\n",
       "      <td>0.040224</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020520</td>\n",
       "      <td>-0.015699</td>\n",
       "      <td>0.033186</td>\n",
       "      <td>-0.032393</td>\n",
       "      <td>0.011923</td>\n",
       "      <td>-0.047880</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>0.021583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30095 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5    \\\n",
       "CUI                                                                    \n",
       "C0443935 -0.005615  0.053907  0.064127 -0.017119 -0.012609 -0.003468   \n",
       "C0228201  0.056639  0.024973  0.043039 -0.010606  0.000297  0.028830   \n",
       "C0269672  0.006275  0.035234 -0.005638  0.052735  0.027593 -0.034095   \n",
       "C0010042  0.005165 -0.007816  0.005519  0.005191 -0.019536 -0.018363   \n",
       "C0496763  0.026411 -0.022139 -0.022034  0.004155 -0.004436 -0.003643   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "C0023755 -0.040562 -0.008575 -0.029939 -0.030448 -0.014047 -0.035917   \n",
       "C0936139 -0.064008  0.010879 -0.021988 -0.007444 -0.018371 -0.035955   \n",
       "C0030569 -0.002874 -0.014771 -0.009262  0.051636  0.058948  0.006536   \n",
       "C0018546 -0.023810 -0.026229  0.087175 -0.021138 -0.013072 -0.026806   \n",
       "C0154685  0.017202  0.044326  0.013208  0.031104  0.040224 -0.049643   \n",
       "\n",
       "               6         7         8         9    ...       502       503  \\\n",
       "CUI                                               ...                       \n",
       "C0443935 -0.030486  0.009772 -0.011773  0.035155  ... -0.027201  0.014443   \n",
       "C0228201 -0.005639 -0.012716  0.016615  0.013446  ...  0.014388 -0.021831   \n",
       "C0269672 -0.000909  0.021540 -0.006118 -0.005323  ... -0.013453  0.033583   \n",
       "C0010042  0.034065 -0.018858 -0.015806 -0.023911  ...  0.058378 -0.045572   \n",
       "C0496763  0.021189  0.009137 -0.017519 -0.109941  ... -0.010080  0.062235   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "C0023755 -0.040634 -0.004045 -0.017335  0.035398  ... -0.020937 -0.002889   \n",
       "C0936139  0.007486  0.021128  0.004214  0.035066  ...  0.014685  0.008963   \n",
       "C0030569 -0.007807  0.015736  0.027136  0.018170  ... -0.019772 -0.030501   \n",
       "C0018546 -0.016932  0.047351 -0.030469  0.048636  ... -0.000437  0.005676   \n",
       "C0154685  0.010588  0.005943  0.038835  0.015438  ... -0.020520 -0.015699   \n",
       "\n",
       "               504       505       506       507       508       509  \\\n",
       "CUI                                                                    \n",
       "C0443935  0.041107  0.013423 -0.017699 -0.050566  0.031370 -0.039818   \n",
       "C0228201 -0.002546  0.021870 -0.042337  0.015798 -0.023749 -0.002659   \n",
       "C0269672 -0.053264  0.001736  0.028285  0.029924 -0.042194 -0.005361   \n",
       "C0010042  0.005460  0.016206 -0.040299  0.009157  0.008565  0.010859   \n",
       "C0496763 -0.018077  0.057734  0.001609 -0.048640 -0.014018 -0.063896   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "C0023755  0.027856 -0.003465 -0.005584  0.009166 -0.024980 -0.030805   \n",
       "C0936139  0.012840  0.004448  0.025604 -0.003902  0.024526 -0.015511   \n",
       "C0030569  0.002406 -0.005095  0.005002 -0.000051 -0.015331  0.002154   \n",
       "C0018546  0.006722 -0.008057  0.024764  0.006442  0.024149 -0.010890   \n",
       "C0154685  0.033186 -0.032393  0.011923 -0.047880  0.010090  0.042791   \n",
       "\n",
       "               510       511  \n",
       "CUI                           \n",
       "C0443935  0.023471  0.046554  \n",
       "C0228201  0.094336  0.010797  \n",
       "C0269672 -0.005018 -0.019387  \n",
       "C0010042 -0.001495  0.043285  \n",
       "C0496763 -0.019638  0.014158  \n",
       "...            ...       ...  \n",
       "C0023755 -0.022126 -0.010326  \n",
       "C0936139 -0.048765 -0.012535  \n",
       "C0030569  0.024111  0.015845  \n",
       "C0018546  0.018251  0.030575  \n",
       "C0154685  0.014453  0.021583  \n",
       "\n",
       "[30095 rows x 512 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kge_embeddings['TransE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = kge_embeddings['TransE']\n",
    "# dataset = cui2vec\n",
    "# dataset = snomed2vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset, num_epoch=20):    \n",
    "    train, test, train_labels, test_labels = split_dataset(dataset)\n",
    "    train_embeddings = torch.tensor(train.to_numpy()).float()\n",
    "    test_embeddings = torch.tensor(test.to_numpy()).float()\n",
    "    train_labels = torch.tensor([label_map[label] for label in train_labels], dtype=torch.long)\n",
    "    test_labels = torch.tensor([label_map[label] for label in test_labels], dtype=torch.long)\n",
    "\n",
    "    train_dataset = TensorDataset(train_embeddings, train_labels)\n",
    "    test_dataset = TensorDataset(test_embeddings, test_labels)\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=64)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "    dim = train.shape[1]\n",
    "    \n",
    "    model = NodeClassifier(dim, 4)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.zero_grad()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    optimizer.zero_grad()\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(num_epoch):\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            \n",
    "            print(batch)\n",
    "            \n",
    "            inputs, labels = tuple(t.to(device) for t in batch)\n",
    "            logits = model(inputs)\n",
    "            loss = loss_fct(logits, labels)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        results = evaluate(model, test_dataloader)\n",
    "        print('epoch acc: {}'.format(results['acc']))\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_labels = model['labels'].value_counts()[models['TransE']['labels'].value_counts()>25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease or Syndrome                        6857\n",
       "Organic Chemical                           3558\n",
       "Finding                                    3257\n",
       "Amino Acid, Peptide, or Protein            1970\n",
       "Body Part, Organ, or Organ Component       1874\n",
       "Injury or Poisoning                        1862\n",
       "Therapeutic or Preventive Procedure        1814\n",
       "Neoplastic Process                         1672\n",
       "Pathologic Function                        1246\n",
       "Congenital Abnormality                      797\n",
       "Sign or Symptom                             751\n",
       "Laboratory Procedure                        554\n",
       "Mental or Behavioral Dysfunction            553\n",
       "Diagnostic Procedure                        513\n",
       "Pharmacologic Substance                     415\n",
       "Body Location or Region                     311\n",
       "Acquired Abnormality                        302\n",
       "Body Space or Junction                      256\n",
       "Anatomical Abnormality                      256\n",
       "Health Care Activity                        229\n",
       "Body Substance                              170\n",
       "Nucleic Acid, Nucleoside, or Nucleotide     151\n",
       "Tissue                                      136\n",
       "Clinical Drug                               100\n",
       "Cell or Molecular Dysfunction                80\n",
       "Hazardous or Poisonous Substance             68\n",
       "Indicator, Reagent, or Diagnostic Aid        65\n",
       "Inorganic Chemical                           64\n",
       "Immunologic Factor                           55\n",
       "Body System                                  48\n",
       "Biologically Active Substance                41\n",
       "Educational Activity                         29\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acquired Abnormality',\n",
       " 'Amino Acid, Peptide, or Protein',\n",
       " 'Anatomical Abnormality',\n",
       " 'Anatomical Structure',\n",
       " 'Antibiotic',\n",
       " 'Biologically Active Substance',\n",
       " 'Biomedical or Dental Material',\n",
       " 'Body Location or Region',\n",
       " 'Body Part, Organ, or Organ Component',\n",
       " 'Body Space or Junction',\n",
       " 'Body Substance',\n",
       " 'Body System',\n",
       " 'Cell or Molecular Dysfunction',\n",
       " 'Clinical Drug',\n",
       " 'Congenital Abnormality',\n",
       " 'Diagnostic Procedure',\n",
       " 'Disease or Syndrome',\n",
       " 'Educational Activity',\n",
       " 'Element, Ion, or Isotope',\n",
       " 'Finding',\n",
       " 'Fully Formed Anatomical Structure',\n",
       " 'Hazardous or Poisonous Substance',\n",
       " 'Health Care Activity',\n",
       " 'Hormone',\n",
       " 'Immunologic Factor',\n",
       " 'Indicator, Reagent, or Diagnostic Aid',\n",
       " 'Injury or Poisoning',\n",
       " 'Inorganic Chemical',\n",
       " 'Laboratory Procedure',\n",
       " 'Mental or Behavioral Dysfunction',\n",
       " 'Molecular Biology Research Technique',\n",
       " 'Neoplastic Process',\n",
       " 'Nucleic Acid, Nucleoside, or Nucleotide',\n",
       " 'Organic Chemical',\n",
       " 'Pathologic Function',\n",
       " 'Pharmacologic Substance',\n",
       " 'Research Activity',\n",
       " 'Sign or Symptom',\n",
       " 'Therapeutic or Preventive Procedure',\n",
       " 'Tissue',\n",
       " 'Vitamin'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(model['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUI\n",
       "C0443935        Amino Acid, Peptide, or Protein\n",
       "C0228201                 Body Space or Junction\n",
       "C0269672                    Pathologic Function\n",
       "C0010042    Therapeutic or Preventive Procedure\n",
       "C0496763                     Neoplastic Process\n",
       "                           ...                 \n",
       "C0023755                       Organic Chemical\n",
       "C0936139                       Organic Chemical\n",
       "C0030569                    Disease or Syndrome\n",
       "C0018546                       Organic Chemical\n",
       "C0154685                    Disease or Syndrome\n",
       "Name: labels, Length: 30095, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['TransE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DISO    17633\n",
       "CHEM     6511\n",
       "PROC     3147\n",
       "ANAT     2804\n",
       "OBJC        1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['snomed2vec']['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DISO    17633\n",
       "CHEM     6511\n",
       "PROC     3147\n",
       "ANAT     2804\n",
       "OBJC        1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['cui2vec']['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TransE\n",
      "[tensor([[-0.0313, -0.0153,  0.0024,  ..., -0.0529, -0.0065, -0.0062],\n",
      "        [ 0.0181, -0.0050,  0.0216,  ..., -0.0054,  0.0076, -0.0274],\n",
      "        [-0.0208, -0.0397,  0.0437,  ...,  0.0197,  0.0694,  0.0284],\n",
      "        ...,\n",
      "        [ 0.0020, -0.0048, -0.0056,  ..., -0.0421,  0.0070, -0.0259],\n",
      "        [-0.0042,  0.0186,  0.0371,  ...,  0.0239,  0.0378,  0.0039],\n",
      "        [ 0.0241, -0.0250,  0.0069,  ...,  0.0270, -0.0043,  0.0316]]), tensor([1, 2, 2, 2, 1, 1, 2, 1, 0, 4, 2, 1, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 0, 2,\n",
      "        1, 1, 2, 0, 2, 1, 1, 1, 0, 0, 0, 0, 4, 2, 2, 0, 1, 2, 0, 1, 0, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 1, 2, 1, 2, 4, 2, 2, 2, 2, 2, 2])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /tmp/pip-req-build-p5q91txh/aten/src/THC/THCTensorMathCompareT.cuh:69",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f07b3781c751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-1425b985ca98>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(dataset, num_epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36misfinite\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /tmp/pip-req-build-p5q91txh/aten/src/THC/THCTensorMathCompareT.cuh:69"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = 0\n",
    "for name, embeddings in models.items():\n",
    "    print('running {}'.format(name))\n",
    "    run_experiment(embeddings, num_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults: exactly the ordering of performance; cui2vec is worst, snomed2vec is better, but not as good as kge models.\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "results: exactly the ordering of performance; cui2vec is worst, snomed2vec is better, but not as good as kge models.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
