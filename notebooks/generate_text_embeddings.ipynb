{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embeddings for textual descriptors in snomed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'bert-base-uncased'\n",
    "# model_type = 'clinicalbert'\n",
    "model_type = 'ccbert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'bert-base-uncased':\n",
    "    pretrained_weights = 'bert-base-uncased'\n",
    "    config = BertConfig.from_pretrained(pretrained_weights)\n",
    "    tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=True)\n",
    "    model = BertModel.from_pretrained(pretrained_weights, config=config)\n",
    "    model.to(device);\n",
    "elif model_type == 'clinicalbert':\n",
    "    config_name = '/home/dc925/project/data/models/clinicalbert/config.json'\n",
    "    tokenizer_name = '/home/dc925/project/data/models/clinicalbert/vocab.txt'\n",
    "    model_name = '/home/dc925/project/data/models/clinicalbert/pytorch_model.bin'\n",
    "    config = BertConfig.from_pretrained(config_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(tokenizer_name, do_lower_case=True)\n",
    "    model = BertModel.from_pretrained(model_name, config=config)\n",
    "    model.to(device);\n",
    "elif model_type == 'ccbert':\n",
    "    config_name = '/home/dc925/project/data/models/ccbert/config.json'\n",
    "    tokenizer_name = '/home/dc925/project/data/models/ccbert/vocab.txt'\n",
    "    model_name = '/home/dc925/project/data/models/ccbert/pytorch_model.bin'\n",
    "    config = BertConfig.from_pretrained(config_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(tokenizer_name, do_lower_case=True)\n",
    "    model = BertModel.from_pretrained(model_name, config=config)\n",
    "    model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need cui2string and relations\n",
    "relations = pd.read_csv('snomed_relations.csv')\n",
    "relation_examples = list(relations['relations'])\n",
    "encoded_relations = torch.tensor([tokenizer.encode(t, max_length=64, pad_to_max_length=True) for t in relation_examples], dtype=torch.long)\n",
    "relation_dataset = TensorDataset(encoded_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('snomed_cui2string.json', 'r') as fin:\n",
    "    concepts = json.load(fin)\n",
    "concept_df = pd.DataFrame.from_dict(concepts, orient='index', columns=['string'])\n",
    "concept_df.to_csv('concepts_df.csv')\n",
    "concept_examples = list(concept_df['string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_concepts = torch.tensor([tokenizer.encode(t, max_length=64, pad_to_max_length=True) for t in concept_examples], dtype=torch.long)\n",
    "# torch.save(encoded_concepts, 'cached_encoded_concepts_clinical')\n",
    "# encoded_concepts = torch.load('cached_encoded_concepts_clinical')\n",
    "concept_dataset = TensorDataset(encoded_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = concept_dataset + relation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "sampler = SequentialSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting features: 100%|██████████| 2298/2298 [10:08<00:00,  3.78it/s]\n"
     ]
    }
   ],
   "source": [
    "logits = None\n",
    "for batch in tqdm(dataloader, desc='extracting features'):\n",
    "    model.eval()\n",
    "    inputs = {'input_ids': batch[0].to(device)}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs['input_ids'])\n",
    "        outputs = outputs[1]\n",
    "        \n",
    "    if logits is None:\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "    else:\n",
    "        logits = np.append(logits, outputs.detach().cpu().numpy(), axis=0)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca took 21.039462566375732\n"
     ]
    }
   ],
   "source": [
    "#dimensionality reduction\n",
    "start = time.time()\n",
    "pca = PCA(n_components=512)\n",
    "pca_out = pca.fit_transform(logits)\n",
    "print('pca took {}'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embeddings = pca_out[:-170]\n",
    "relation_embeddings = pca_out[-170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccbert\n"
     ]
    }
   ],
   "source": [
    "print(model_type)\n",
    "if model_type == 'bert-base-uncased':\n",
    "    np.save('data/case4/concept_embeddings_bert', concept_embeddings)\n",
    "    np.save('data/case4/relation_embeddings_bert', relation_embeddings)\n",
    "elif model_type=='clinicalbert':\n",
    "    np.save('data/case4/concept_embeddings_clinicalbert', concept_embeddings)\n",
    "    np.save('data/case4/relation_embeddings_clinicalbert', relation_embeddings)\n",
    "elif model_type=='ccbert':\n",
    "    np.save('data/case4/concept_embeddings_ccbert', concept_embeddings)\n",
    "    np.save('data/case4/relation_embeddings_ccbert', relation_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
